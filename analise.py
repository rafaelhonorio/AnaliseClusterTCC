# -*- coding: utf-8 -*-
"""Analise.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10S9eIBjOAAlYLuH_RkrPpVfuNoHhCNme
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install kmodes

import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from sklearn.metrics import pairwise_distances
from kmodes.kprototypes import KPrototypes

from google.colab import drive
 drive.mount('/content/drive')

renameCols = {
    'Qual sua idade?': "idade",
    'Já sabia programar antes de entrar na UnB?': "sabe_programar",
    'Fez o ensino médio em escola pública ou particular?': "escola_publica",
    'Quanto tempo demora para chegar na Universidade?': "tempo_chegar",
}

df = pd.read_excel("/content/drive/MyDrive/tabela_clusters.xlsx", sheet_name="base toda").rename(columns=renameCols)
df.columns

"""### Fazendo uma melhor representação de features categoricas ordinais"""

df_cleaned = df.drop(columns=["Nome Completo"])

df_cleaned.columns

"""### Fazendo Scaling das features

O algoritmo Kmeans é sensivel a escala das features a serem utilizadas por ser feito utilizando distancia euclidiana entre os pontos. O objetivo do scaling é colocar todas as features entre 0 e 1.
"""

categorical_data = ["idade"]

continuous_data = ["tempo_chegar", 'escola_publica', 'sabe_programar']

scaler = StandardScaler()
scaled_data = scaler.fit_transform(df_cleaned[continuous_data])
scaled_continuous_df = pd.DataFrame(scaled_data, columns=continuous_data)

final_df = pd.concat([scaled_continuous_df, df_cleaned[categorical_data]], axis=1)
categorical_data_indexes = list(map(final_df.columns.get_loc, categorical_data))
categorical_data_indexes

"""# Kmeans com dados possuindo categoricas booleanas

## Metodo do Cotovelo

The elbow method is a heuristic used to determine the optimal number of clusters in a dataset for K-means clustering. It involves running K-means clustering for a range of values of K and plotting the within-cluster sum of squares (WCSS) against the number of clusters. The "elbow" point in the plot, where the rate of decrease in WCSS slows down, indicates the optimal number of clusters.
"""

# Range of clusters to test
k_values = range(1, 10)  # Test from 1 to 10 clusters

# Store the within-cluster sum of squares (WCSS) for each value of K
wcss = []

# Calculate WCSS for each value of K
for k in k_values:
    kprototypes = KPrototypes(n_clusters=k, random_state=1337, n_jobs=-1)
    kprototypes.fit(final_df, categorical = categorical_data_indexes)
    wcss.append(kprototypes.cost_)

# Plot the elbow curve
plt.plot(k_values, wcss, marker='o')
plt.title('Método do Cotovelo')
plt.xlabel('N° de Clusters')
plt.ylabel('Custo')
plt.xticks(k_values)
plt.show()

"""## Aplicando KPrototype

O numero otimo de clusters esta entre 2 a 4 clusters
"""

kprototypes = KPrototypes(n_clusters=2, random_state=1337, n_jobs=-1)
cluster_labels = kprototypes.fit(df_cleaned, categorical = categorical_data_indexes)

df['cluster'] = kprototypes.labels_
df['cluster_name'] = "cluster_" + df["cluster"].astype(str)

"""## Visualizando os clusters utilizando redução de dimensionalidade"""

features = df_cleaned
# features["scaled_data"] = scaled_data
features.columns

"""### TSNE"""

# Aplicando o t-SNE
tsne = TSNE(n_components=2, random_state=0, perplexity=30)
projections = tsne.fit_transform(final_df)

# Criando o gráfico
fig = px.scatter(
    x=projections[:, 0], y=projections[:, 1],
    color=df.cluster_name, labels={'color': 'Nome Cluster'}
)

# Melhorando a visualização
fig.update_traces(marker=dict(size=8))  # Aumenta o tamanho dos pontos
fig.update_layout(
    width=800, height=600,  # Ajusta o tamanho da figura
    xaxis_title='Componente 1',
    yaxis_title='Componente 2',
)

# Exibindo o gráfico
fig.show()

"""## Visualizando as features de maneira individual"""

from plotly.subplots import make_subplots

num_rows = 1
num_cols = 4

fig = make_subplots(rows=num_rows, cols=num_cols)

for i, feature in enumerate(features, start=1):
  row = ((i - 1) // num_cols) + 1
  col = ((i - 1) % num_cols) + 1

  fig.add_trace(
      go.Box(x=df["cluster_name"], y=df[feature], name=feature),
      row=row,
      col=col
  )

fig.update_layout(
                  height=500,  # Adjust height as needed
                  width=1000)  # Adjust width as needed

fig.show()

from plotly.subplots import make_subplots

num_rows = 1
num_cols = 4

fig = make_subplots(rows=num_rows, cols=num_cols)

for i, feature in enumerate(features, start=1):
  row = ((i - 1) // num_cols) + 1
  col = ((i - 1) % num_cols) + 1

  fig.add_trace(
      go.Violin(x=df["cluster_name"],
                y=df[feature],
                name=feature,
                meanline_visible=True,
                # box_visible=True),
      ),
      row=row,
      col=col
  )

fig.update_layout(
                  violinmode='overlay',
                  height=500,  # Adjust height as needed
                  width=1000)  # Adjust width as needed

fig.show()

with pd.ExcelWriter('/content/drive/MyDrive/tabela_clusters_KPrototype_Rafael.xlsx') as writer:
    df.to_excel(writer, sheet_name='clusters')
    df[["Nome Completo", "cluster"]].to_excel(writer, sheet_name='base toda')

